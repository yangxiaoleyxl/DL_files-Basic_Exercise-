{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T02:40:30.481637Z",
     "start_time": "2018-12-13T02:36:35.604497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 2, 8, 16)          80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 4, 8)           520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 2, 8)           4104      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 8)           264       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 2, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 4, 16)          1040      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 2, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 8, 1)           65        \n",
      "=================================================================\n",
      "Total params: 6,073\n",
      "Trainable params: 6,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "8400/8400 [==============================] - 2s 277us/step - loss: 0.6159 - val_loss: 0.5599\n",
      "Epoch 2/100\n",
      "8400/8400 [==============================] - 1s 170us/step - loss: 0.5399 - val_loss: 0.5058\n",
      "Epoch 3/100\n",
      "8400/8400 [==============================] - 2s 181us/step - loss: 0.4754 - val_loss: 0.4572\n",
      "Epoch 4/100\n",
      "8400/8400 [==============================] - 1s 167us/step - loss: 0.4438 - val_loss: 0.4175\n",
      "Epoch 5/100\n",
      "8400/8400 [==============================] - 1s 168us/step - loss: 0.3827 - val_loss: 0.3641\n",
      "Epoch 6/100\n",
      "8400/8400 [==============================] - 1s 170us/step - loss: 0.3507 - val_loss: 0.3402\n",
      "Epoch 7/100\n",
      "8400/8400 [==============================] - 1s 168us/step - loss: 0.3328 - val_loss: 0.3269\n",
      "Epoch 8/100\n",
      "8400/8400 [==============================] - 1s 163us/step - loss: 0.3216 - val_loss: 0.3177\n",
      "Epoch 9/100\n",
      "8400/8400 [==============================] - 1s 170us/step - loss: 0.3133 - val_loss: 0.3139\n",
      "Epoch 10/100\n",
      "8400/8400 [==============================] - 1s 177us/step - loss: 0.3072 - val_loss: 0.3061\n",
      "Epoch 11/100\n",
      "8400/8400 [==============================] - 1s 165us/step - loss: 0.3021 - val_loss: 0.3024\n",
      "Epoch 12/100\n",
      "8400/8400 [==============================] - 1s 165us/step - loss: 0.2974 - val_loss: 0.2951\n",
      "Epoch 13/100\n",
      "8400/8400 [==============================] - 2s 186us/step - loss: 0.2930 - val_loss: 0.2905\n",
      "Epoch 14/100\n",
      "8400/8400 [==============================] - 1s 171us/step - loss: 0.2876 - val_loss: 0.2884\n",
      "Epoch 15/100\n",
      "8400/8400 [==============================] - 2s 194us/step - loss: 0.2821 - val_loss: 0.2788\n",
      "Epoch 16/100\n",
      "8400/8400 [==============================] - 2s 219us/step - loss: 0.2748 - val_loss: 0.2713\n",
      "Epoch 17/100\n",
      "8400/8400 [==============================] - 2s 211us/step - loss: 0.2660 - val_loss: 0.2637\n",
      "Epoch 18/100\n",
      "8400/8400 [==============================] - 2s 205us/step - loss: 0.2556 - val_loss: 0.2581\n",
      "Epoch 19/100\n",
      "8400/8400 [==============================] - 2s 206us/step - loss: 0.2442 - val_loss: 0.2392\n",
      "Epoch 20/100\n",
      "8400/8400 [==============================] - 2s 228us/step - loss: 0.2342 - val_loss: 0.2263\n",
      "Epoch 21/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.2251 - val_loss: 0.2184\n",
      "Epoch 22/100\n",
      "8400/8400 [==============================] - 2s 202us/step - loss: 0.2163 - val_loss: 0.2110\n",
      "Epoch 23/100\n",
      "8400/8400 [==============================] - 2s 205us/step - loss: 0.2080 - val_loss: 0.2022\n",
      "Epoch 24/100\n",
      "8400/8400 [==============================] - 2s 203us/step - loss: 0.1980 - val_loss: 0.1975\n",
      "Epoch 25/100\n",
      "8400/8400 [==============================] - 2s 203us/step - loss: 0.1873 - val_loss: 0.1811\n",
      "Epoch 26/100\n",
      "8400/8400 [==============================] - 2s 199us/step - loss: 0.1738 - val_loss: 0.1669\n",
      "Epoch 27/100\n",
      "8400/8400 [==============================] - 2s 199us/step - loss: 0.1589 - val_loss: 0.1534\n",
      "Epoch 28/100\n",
      "8400/8400 [==============================] - 2s 200us/step - loss: 0.1457 - val_loss: 0.1442\n",
      "Epoch 29/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.1357 - val_loss: 0.1347\n",
      "Epoch 30/100\n",
      "8400/8400 [==============================] - 2s 201us/step - loss: 0.1243 - val_loss: 0.1244\n",
      "Epoch 31/100\n",
      "8400/8400 [==============================] - 2s 196us/step - loss: 0.1141 - val_loss: 0.1132\n",
      "Epoch 32/100\n",
      "8400/8400 [==============================] - 2s 202us/step - loss: 0.1058 - val_loss: 0.1026\n",
      "Epoch 33/100\n",
      "8400/8400 [==============================] - 2s 201us/step - loss: 0.0997 - val_loss: 0.1156\n",
      "Epoch 34/100\n",
      "8400/8400 [==============================] - 2s 201us/step - loss: 0.0937 - val_loss: 0.0940\n",
      "Epoch 35/100\n",
      "8400/8400 [==============================] - 2s 207us/step - loss: 0.0881 - val_loss: 0.0917\n",
      "Epoch 36/100\n",
      "8400/8400 [==============================] - 2s 215us/step - loss: 0.0859 - val_loss: 0.0853\n",
      "Epoch 37/100\n",
      "8400/8400 [==============================] - 2s 206us/step - loss: 0.0818 - val_loss: 0.0859\n",
      "Epoch 38/100\n",
      "8400/8400 [==============================] - 2s 214us/step - loss: 0.0790 - val_loss: 0.0789\n",
      "Epoch 39/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.0764 - val_loss: 0.0773\n",
      "Epoch 40/100\n",
      "8400/8400 [==============================] - 2s 199us/step - loss: 0.0730 - val_loss: 0.0713\n",
      "Epoch 41/100\n",
      "8400/8400 [==============================] - 2s 204us/step - loss: 0.0709 - val_loss: 0.0697\n",
      "Epoch 42/100\n",
      "8400/8400 [==============================] - 2s 212us/step - loss: 0.0688 - val_loss: 0.0708\n",
      "Epoch 43/100\n",
      "8400/8400 [==============================] - 2s 199us/step - loss: 0.0668 - val_loss: 0.0887\n",
      "Epoch 44/100\n",
      "8400/8400 [==============================] - 2s 200us/step - loss: 0.0648 - val_loss: 0.0636\n",
      "Epoch 45/100\n",
      "8400/8400 [==============================] - 2s 221us/step - loss: 0.0620 - val_loss: 0.0621\n",
      "Epoch 46/100\n",
      "8400/8400 [==============================] - 2s 217us/step - loss: 0.0595 - val_loss: 0.0607\n",
      "Epoch 47/100\n",
      "8400/8400 [==============================] - 2s 209us/step - loss: 0.0579 - val_loss: 0.0559\n",
      "Epoch 48/100\n",
      "8400/8400 [==============================] - 2s 216us/step - loss: 0.0575 - val_loss: 0.0575\n",
      "Epoch 49/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.0555 - val_loss: 0.0589\n",
      "Epoch 50/100\n",
      "8400/8400 [==============================] - 2s 204us/step - loss: 0.0569 - val_loss: 0.0530\n",
      "Epoch 51/100\n",
      "8400/8400 [==============================] - 2s 222us/step - loss: 0.0528 - val_loss: 0.0502\n",
      "Epoch 52/100\n",
      "8400/8400 [==============================] - 2s 207us/step - loss: 0.0510 - val_loss: 0.0486\n",
      "Epoch 53/100\n",
      "8400/8400 [==============================] - 2s 218us/step - loss: 0.0500 - val_loss: 0.0570\n",
      "Epoch 54/100\n",
      "8400/8400 [==============================] - 2s 205us/step - loss: 0.0487 - val_loss: 0.0516\n",
      "Epoch 55/100\n",
      "8400/8400 [==============================] - 2s 219us/step - loss: 0.0465 - val_loss: 0.0482\n",
      "Epoch 56/100\n",
      "8400/8400 [==============================] - 2s 199us/step - loss: 0.0451 - val_loss: 0.0427\n",
      "Epoch 57/100\n",
      "8400/8400 [==============================] - 2s 208us/step - loss: 0.0445 - val_loss: 0.0443\n",
      "Epoch 58/100\n",
      "8400/8400 [==============================] - 2s 215us/step - loss: 0.0439 - val_loss: 0.0413\n",
      "Epoch 59/100\n",
      "8400/8400 [==============================] - 2s 180us/step - loss: 0.0422 - val_loss: 0.0532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "8400/8400 [==============================] - 1s 171us/step - loss: 0.0419 - val_loss: 0.0486\n",
      "Epoch 61/100\n",
      "8400/8400 [==============================] - 1s 175us/step - loss: 0.0410 - val_loss: 0.0402\n",
      "Epoch 62/100\n",
      "8400/8400 [==============================] - 2s 191us/step - loss: 0.0487 - val_loss: 0.0419\n",
      "Epoch 63/100\n",
      "8400/8400 [==============================] - 2s 185us/step - loss: 0.0385 - val_loss: 0.0386\n",
      "Epoch 64/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.0368 - val_loss: 0.0411\n",
      "Epoch 65/100\n",
      "8400/8400 [==============================] - 1s 173us/step - loss: 0.0367 - val_loss: 0.0350\n",
      "Epoch 66/100\n",
      "8400/8400 [==============================] - 1s 177us/step - loss: 0.0359 - val_loss: 0.0331\n",
      "Epoch 67/100\n",
      "8400/8400 [==============================] - 1s 174us/step - loss: 0.0348 - val_loss: 0.0358\n",
      "Epoch 68/100\n",
      "8400/8400 [==============================] - 2s 179us/step - loss: 0.0351 - val_loss: 0.0311\n",
      "Epoch 69/100\n",
      "8400/8400 [==============================] - 2s 193us/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 70/100\n",
      "8400/8400 [==============================] - 1s 172us/step - loss: 0.0342 - val_loss: 0.0354\n",
      "Epoch 71/100\n",
      "8400/8400 [==============================] - 2s 187us/step - loss: 0.0359 - val_loss: 0.0306\n",
      "Epoch 72/100\n",
      "8400/8400 [==============================] - 2s 183us/step - loss: 0.0327 - val_loss: 0.0280\n",
      "Epoch 73/100\n",
      "8400/8400 [==============================] - 2s 193us/step - loss: 0.0308 - val_loss: 0.0408\n",
      "Epoch 74/100\n",
      "8400/8400 [==============================] - 2s 192us/step - loss: 0.0317 - val_loss: 0.0272\n",
      "Epoch 75/100\n",
      "8400/8400 [==============================] - 2s 186us/step - loss: 0.0306 - val_loss: 0.0256\n",
      "Epoch 76/100\n",
      "8400/8400 [==============================] - 2s 205us/step - loss: 0.0277 - val_loss: 0.0250\n",
      "Epoch 77/100\n",
      "8400/8400 [==============================] - 2s 205us/step - loss: 0.0282 - val_loss: 0.0274\n",
      "Epoch 78/100\n",
      "8400/8400 [==============================] - 2s 187us/step - loss: 0.0279 - val_loss: 0.0254\n",
      "Epoch 79/100\n",
      "8400/8400 [==============================] - 2s 189us/step - loss: 0.0264 - val_loss: 0.0227\n",
      "Epoch 80/100\n",
      "8400/8400 [==============================] - 2s 182us/step - loss: 0.0269 - val_loss: 0.0262\n",
      "Epoch 81/100\n",
      "8400/8400 [==============================] - 1s 178us/step - loss: 0.0252 - val_loss: 0.0468\n",
      "Epoch 82/100\n",
      "8400/8400 [==============================] - 2s 194us/step - loss: 0.0271 - val_loss: 0.0225\n",
      "Epoch 83/100\n",
      "8400/8400 [==============================] - 2s 211us/step - loss: 0.0274 - val_loss: 0.0201\n",
      "Epoch 84/100\n",
      "8400/8400 [==============================] - 2s 203us/step - loss: 0.0233 - val_loss: 0.0195\n",
      "Epoch 85/100\n",
      "8400/8400 [==============================] - 2s 217us/step - loss: 0.0245 - val_loss: 0.0201\n",
      "Epoch 86/100\n",
      "8400/8400 [==============================] - 2s 225us/step - loss: 0.0224 - val_loss: 0.0202\n",
      "Epoch 87/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.0204 - val_loss: 0.0177\n",
      "Epoch 88/100\n",
      "8400/8400 [==============================] - 2s 228us/step - loss: 0.0210 - val_loss: 0.0298\n",
      "Epoch 89/100\n",
      "8400/8400 [==============================] - 1s 178us/step - loss: 0.0217 - val_loss: 0.0180\n",
      "Epoch 90/100\n",
      "8400/8400 [==============================] - 2s 182us/step - loss: 0.0218 - val_loss: 0.0193\n",
      "Epoch 91/100\n",
      "8400/8400 [==============================] - 2s 187us/step - loss: 0.0199 - val_loss: 0.0192\n",
      "Epoch 92/100\n",
      "8400/8400 [==============================] - 2s 182us/step - loss: 0.0195 - val_loss: 0.0163\n",
      "Epoch 93/100\n",
      "8400/8400 [==============================] - 1s 176us/step - loss: 0.0173 - val_loss: 0.0155\n",
      "Epoch 94/100\n",
      "8400/8400 [==============================] - 2s 196us/step - loss: 0.0176 - val_loss: 0.0236\n",
      "Epoch 95/100\n",
      "8400/8400 [==============================] - 2s 189us/step - loss: 0.0221 - val_loss: 0.0403\n",
      "Epoch 96/100\n",
      "8400/8400 [==============================] - 2s 193us/step - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 97/100\n",
      "8400/8400 [==============================] - 2s 213us/step - loss: 0.0175 - val_loss: 0.0148\n",
      "Epoch 98/100\n",
      "8400/8400 [==============================] - 2s 223us/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 99/100\n",
      "8400/8400 [==============================] - 2s 212us/step - loss: 0.0155 - val_loss: 0.0189\n",
      "Epoch 100/100\n",
      "8400/8400 [==============================] - 2s 201us/step - loss: 0.0145 - val_loss: 0.0233\n"
     ]
    }
   ],
   "source": [
    "from keras import *\n",
    "from keras.layers import Dense,Conv2D,Conv1D,MaxPooling2D, UpSampling2D,Embedding\n",
    "from keras.models import Model,Sequential\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_preprocessing \n",
    "import os,scipy\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto(device_count={'gpu':0})\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.9  # 为显卡利用率设置阈值\n",
    "# set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "num_sample = 12000\n",
    "cut_point = int(0.7 * num_sample)\n",
    "bit  = 1\n",
    "bit_k = 8\n",
    "category = pow(2,bit_k)\n",
    "r_dim = 1\n",
    "\n",
    "epoch = 100\n",
    "batch_size = 25\n",
    "\n",
    "##  这里是numpy下进行one-hot编码的函数，\n",
    "##  不同于pandas下的直接调用get_dummies,pandas中设计 Dataframe 的转化\n",
    "def convert_to_one_hot(y, C):\n",
    "    return np.eye(C)[y.reshape(-1)]\n",
    "\n",
    "# source = ['0000','0001','0010','0011',\n",
    "#           '0100','0101','0110','0111',\n",
    "#           '1000','1001','1010','1011',\n",
    "#           '1100','1101','1110','1111'] \n",
    "\n",
    "I = np.array(np.zeros([num_sample,bit]),dtype=int)\n",
    "Q = np.array(np.zeros([num_sample,bit]),dtype=int)\n",
    "\n",
    "I_k = np.array(np.zeros([num_sample,bit_k]),dtype=int)\n",
    "Q_k = np.array(np.zeros([num_sample,bit_k]),dtype=int)\n",
    "\n",
    "for i in range(num_sample):\n",
    "    \n",
    "    #产生二进制对应的整数\n",
    "    row_I = np.random.randint(16, size=[r_dim,bit],dtype=int)\n",
    "    row_Q = np.random.randint(16, size=[r_dim,bit],dtype=int)\n",
    "    I[i] = row_I\n",
    "    Q[i] = row_Q\n",
    "    \n",
    "    # 产生4位二进制数\n",
    "    row_I_k = np.random.randint(2, size=[r_dim,bit_k],dtype=int)\n",
    "    row_Q_k = np.random.randint(2, size=[r_dim,bit_k],dtype=int)\n",
    "    I_k[i] = row_I_k\n",
    "    Q_k[i] = row_I_k\n",
    "\n",
    "# 构建I路数据集，标签集\n",
    "I_dataset_data = I_k.reshape([num_sample,bit_k])\n",
    "I_dataset_label = convert_to_one_hot(I,category)\n",
    "I_dataset = np.append(I_k,I_dataset_label,axis=1)\n",
    "\n",
    "# 构建Q路数据集，标签集\n",
    "Q_dataset_data = Q_k.reshape([num_sample,bit_k])\n",
    "Q_dataset_label = convert_to_one_hot(Q,category)\n",
    "Q_dataset = np.append(Q_k,Q_dataset_label,axis=1)\n",
    "\n",
    "# 构建IQ数据集，标签集\n",
    "# IQ_dataset_data为IQ数据,共8bit,各4bit\n",
    "# IQ_dataset_label为IQ数据标签，one-hot形式，各16bit,共32bit\n",
    "IQ_dataset_data = np.append(I_dataset_data,Q_dataset_data,axis=1)\n",
    "IQ_dataset_label = np.append(I_dataset_label,Q_dataset_label,axis=1)\n",
    "IQ_dataset = np.append(IQ_dataset_data,IQ_dataset_label,axis=1)\n",
    "# print(IQ_dataset.shape)\n",
    "\n",
    "#############################################################\n",
    "# 这里最终将一个二维数组化为了12000个2*4*1的三维数组，即12000个切片\n",
    "# 后面可以利用Conv2D进行卷积处理 \n",
    "# IQ_data = np.reshape(IQ_dataset_data, (-1,2,bit_k,1))\n",
    "# print(IQ_dataset_label.shape) \n",
    "#############################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(IQ_dataset_data, \n",
    "        IQ_dataset_label,test_size=0.3, random_state=0) # 为了看模型在没有见过数据集上的表现，随机拿出数据集中30%的部分做测试\n",
    "X_train = X_train.reshape(-1,2,bit_k,1)\n",
    "X_test = X_test.reshape(-1,2,bit_k,1)\n",
    "# y_train = X_test.reshape(-1,2,bit_k,1)\n",
    "\n",
    "# print(X_train.shape,X_test.shape)\n",
    "# X_train.reshape(-1,)\n",
    "############ 根据文章自己写的编码器结构 ###############################\n",
    "input_shape = (2,bit_k,1)\n",
    "input_data = Input(input_shape)\n",
    "# x = Conv2D(32,(3,3),activation=\"linear\",padding='same')(input_data)\n",
    "# x = Dense(44,activation='hard_sigmoid')(x)\n",
    "# x = Dense(176,activation='hard_sigmoid')(x)\n",
    "# x = Conv2D(48,(3,3),activation='linear',padding='same')(x)\n",
    "\n",
    "x = Conv2D(16, (2,2), activation='relu', padding='same')(input_data)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "x = Conv2D(8,(2,2), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "x = Conv2D(8, (2,32), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "# 解码器部分\n",
    "x = Conv2D(8, (2,2), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 4))(x)\n",
    "x = Conv2D(16, (2,4), activation='relu', padding='same')(x) \n",
    "x = UpSampling2D((1, 2))(x)\n",
    "decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(inputs=input_data, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n",
    "\n",
    "## 得到编码层的输出\n",
    "# encoder_model = Model(inputs=autoencoder.input, \n",
    "#   outputs=autoencoder.get_layer('encoded').output)\n",
    "autoencoder.fit(X_train,X_train, epochs=epoch, batch_size=batch_size,    \n",
    "                shuffle=True, validation_data=(X_test,X_test),  \n",
    "    callbacks=[TensorBoard(log_dir='./tmp/log')])\n",
    "decoded_data = autoencoder.predict(X_test)\n",
    "# print(decoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T11:29:52.799190Z",
     "start_time": "2018-12-12T11:29:52.794202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 2, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(decoded_data.shape)\n",
    "decoded_data_bk = decoded_data\n",
    "# from sklearn.manifold import TSNE\n",
    "# TSNE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
